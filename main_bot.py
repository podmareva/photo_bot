import os
import io
import base64
import logging
from datetime import datetime
from enum import Enum
from pathlib import Path

from dotenv import load_dotenv
load_dotenv()

import requests
from PIL import Image, ImageFilter
from aiogram import Bot, Dispatcher, types
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram.utils.executor import start_webhook

# == OPTIONAL local free remover ==
try:
    from rembg import remove as rembg_remove
    REMBG_AVAILABLE = True
except Exception:
    REMBG_AVAILABLE = False

# == OpenCV –¥–ª—è –º—è–≥–∫–æ–≥–æ –≤–ø–∏—Å—ã–≤–∞–Ω–∏—è ==
import numpy as np
import cv2

# ====== CONFIG ======
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PIXELCUT_API_KEY = os.getenv("PIXELCUT_API_KEY")
PIXELCUT_ENDPOINT = os.getenv(
    "PIXELCUT_ENDPOINT", "https://api.developer.pixelcut.ai/v1/remove-background"
)

# –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
DATABASE_URL = os.getenv("DATABASE_URL")
ADMIN_ID = int(os.getenv("ADMIN_ID", "0"))
MAIN_BOT_USERNAME = os.getenv("MAIN_BOT_USERNAME", "")

# ====== DB helpers (–≥–∞–ª–µ—Ä–µ—è —Ö—Ä–∞–Ω–∏—Ç —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ file_id) ======
import psycopg2

def db_exec(q, params=()):
    if not DATABASE_URL:
        return None
    conn = psycopg2.connect(DATABASE_URL)
    try:
        with conn, conn.cursor() as cur:
            cur.execute(q, params)
            if cur.description:
                return cur.fetchall()
    finally:
        conn.close()

def gallery_save(
    user_id: int,
    src_file_id: str,
    cut_file_id: str,
    placement: str,
    size_aspect: str,
    style_text: str,
    n_variants: int,
    result_file_ids: list,
):
    if not DATABASE_URL:
        return
    db_exec(
        """INSERT INTO items(user_id, src_file_id, cut_file_id, placement, size_aspect, style_text, n_variants, result_file_ids)
           VALUES (%s,%s,%s,%s,%s,%s,%s,%s)""",
        (
            user_id,
            src_file_id,
            cut_file_id,
            placement,
            size_aspect,
            style_text,
            n_variants,
            result_file_ids,
        ),
    )

def gallery_last(user_id: int):
    if not DATABASE_URL:
        return None
    rows = db_exec(
        """SELECT id, src_file_id, cut_file_id, placement, size_aspect, style_text
           FROM items WHERE user_id=%s ORDER BY created_at DESC LIMIT 1""",
        (user_id,),
    )
    return rows[0] if rows else None

assert BOT_TOKEN, "BOT_TOKEN is required"
assert OPENAI_API_KEY, "OPENAI_API_KEY is required"

logging.basicConfig(level=logging.INFO)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher(bot, storage=MemoryStorage())

import os as _os, logging as _logging
_logging.info("Bot starting‚Ä¶ PID=%s, instance=%s",
             _os.getpid(), _os.getenv("RENDER_INSTANCE_ID"))

async def _log_bot_info():
    me = await bot.get_me()
    logging.info("Bot: @%s (id=%s)", me.username, me.id)

# ===== TEXTS =====
WELCOME = (
    "üëã –ü—Ä–∏–≤–µ—Ç! –¢—ã –≤ –±–æ—Ç–µ ¬´–ü—Ä–µ–¥–º–µ—Ç–Ω—ã–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ¬ª.\n\n"
    "–û–Ω –ø–æ–º–æ–∂–µ—Ç:\n"
    "‚Ä¢ —Å–¥–µ–ª–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–º–µ—Ç–Ω—ã–µ —Ñ–æ—Ç–æ,\n"
    "‚Ä¢ –∑–∞–º–µ–Ω–∏—Ç—å —Ñ–æ–Ω –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Ñ–æ—Ä–º—ã, —Ü–≤–µ—Ç–∞ –∏ –Ω–∞–¥–ø–∏—Å–µ–π,\n"
    "‚Ä¢ —Å–æ–∑–¥–∞—Ç—å –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã–µ —Å—Ü–µ–Ω—ã (—Å—Ç—É–¥–∏–π–Ω–æ / –Ω–∞ —á–µ–ª–æ–≤–µ–∫–µ / –≤ —Ä—É–∫–∞—Ö).\n\n"
    "üîê –ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å, –Ω–∞–∂–º–∏ ¬´–°–¢–ê–†–¢¬ª."
)

REQUIREMENTS = (
    "üì• –î–æ–±–∞–≤—å —Å–≤–æ—ë —Ñ–æ—Ç–æ.\n\n"
    "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∏—Å—Ö–æ–¥–Ω–∏–∫—É –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:\n"
    "‚Ä¢ –†–æ–≤–Ω—ã–π —Å–≤–µ—Ç –±–µ–∑ –∂—ë—Å—Ç–∫–∏—Ö —Ç–µ–Ω–µ–π.\n"
    "‚Ä¢ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π —Ñ–æ–Ω.\n"
    "‚Ä¢ –ü—Ä–µ–¥–º–µ—Ç —Ü–µ–ª–∏–∫–æ–º, –∫—Ä–∞—è –Ω–µ –æ–±—Ä–µ–∑–∞–Ω—ã.\n"
    "‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (–ª—É—á—à–µ ¬´–î–æ–∫—É–º–µ–Ω—Ç¬ª, —á—Ç–æ–±—ã Telegram –Ω–µ —Å–∂–∏–º–∞–ª)."
)

PROMPTS_FILE = Path(__file__).parent / "prompts_cheatsheet.md"

# ====== –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ prompts_cheatsheet.md (–µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞–¥–∏–º) ======
PROMPTS_MD = """# üìì –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ –ø—Ä–æ–º–ø—Ç–∞–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ü–µ–Ω

–û–±—â–µ–µ –ø—Ä–∞–≤–∏–ª–æ: –æ–ø–∏—Å—ã–≤–∞–π —Ç–æ–ª—å–∫–æ —Ñ–æ–Ω/–æ–∫—Ä—É–∂–µ–Ω–∏–µ/—Å–≤–µ—Ç/–Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ. –ù–µ —É–ø–æ–º–∏–Ω–∞–π —Å–∞–º —Ç–æ–≤–∞—Ä.
–ü—Ä–æ–º–ø—Ç—ã ‚Äî –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (—Ç–æ—á–Ω–µ–µ –¥–ª—è –º–æ–¥–µ–ª–∏). –î–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.
–ï—Å–ª–∏ –≤–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∏–¥ —Ç–æ–≤–∞—Ä–∞: add ‚Äî `do not change product color, shape or details`.

---

## 1) –ß–∏—Å—Ç—ã–π –∫–∞—Ç–∞–ª–æ–≥ / —Å—Ç—É–¥–∏—è
- white seamless background, soft studio lighting, natural shadows ‚Äî —á–∏—Å—Ç—ã–π –±–µ–ª—ã–π —Ñ–æ–Ω, –º—è–≥–∫–∏–π —Å–≤–µ—Ç
- light gradient background, minimalism, soft shadows ‚Äî —Å–≤–µ—Ç–ª—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç, –º–∏–Ω–∏–º–∞–ª–∏–∑–º
- clean pastel background, centered composition, no props ‚Äî –ø–∞—Å—Ç–µ–ª—å–Ω—ã–π —Ñ–æ–Ω, –±–µ–∑ —Ä–µ–∫–≤–∏–∑–∏—Ç–∞

## 2) –ú–∏–Ω–∏–º–∞–ª–∏–∑–º
- matte single-color background, pastel tones, soft shadows ‚Äî –º–∞—Ç–æ–≤—ã–π –æ–¥–Ω–æ—Ç–æ–Ω, –º—è–≥–∫–∏–µ —Ç–µ–Ω–∏
- light concrete wall, soft diffused light ‚Äî —Å–≤–µ—Ç–ª—ã–π –±–µ—Ç–æ–Ω, —Ä–∞—Å—Å–µ—è–Ω–Ω—ã–π —Å–≤–µ—Ç
- beige background, airy atmosphere, no props ‚Äî –±–µ–∂–µ–≤—ã–π —Ñ–æ–Ω, ¬´–≤–æ–∑–¥—É—Ö¬ª, –±–µ–∑ —Ä–µ–∫–≤–∏–∑–∏—Ç–∞

## 3) –¢—ë–º–Ω—ã–π –ø—Ä–µ–º–∏—É–º / –¥—Ä–∞–º–∞—Ç–∏—á–Ω—ã–π
- deep black background, dramatic rim light, high contrast ‚Äî —á—ë—Ä–Ω—ã–π —Ñ–æ–Ω, –∫–æ–Ω—Ç—Ä–æ–≤—ã–π —Å–≤–µ—Ç
- dark gradient background, soft highlights, premium look ‚Äî —Ç—ë–º–Ω—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç, –º—è–≥–∫–∏–µ –±–ª–∏–∫–∏
- black velvet texture, macro shot, controlled reflections ‚Äî —á—ë—Ä–Ω—ã–π –±–∞—Ä—Ö–∞—Ç, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è

## 4) –ì–ª—è–Ω–µ—Ü / –∫–∞–º–µ–Ω—å / –º—Ä–∞–º–æ—Ä
- glossy marble surface, dark background, soft studio light ‚Äî –≥–ª—è–Ω—Ü–µ–≤—ã–π –º—Ä–∞–º–æ—Ä, —Ç—ë–º–Ω—ã–π —Ñ–æ–Ω
- black granite surface, focused light ‚Äî —á—ë—Ä–Ω—ã–π –≥—Ä–∞–Ω–∏—Ç, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–≤–µ—Ç
- mirror reflection, product on glass, moody lighting ‚Äî —Å—Ç–µ–∫–ª–æ –∏ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ, –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω—ã–π —Å–≤–µ—Ç

## 5) –ö–æ—Å–º–µ—Ç–∏–∫–∞ / —É—Ö–æ–¥
- frosted glass surface, gradient background, soft glow ‚Äî –º–∞—Ç–æ–≤–æ–µ —Å—Ç–µ–∫–ª–æ, –≥—Ä–∞–¥–∏–µ–Ω—Ç, —Å–≤–µ—á–µ–Ω–∏–µ
- acrylic stand, warm diffused light ‚Äî –∞–∫—Ä–∏–ª–æ–≤–∞—è –ø–æ–¥—Å—Ç–∞–≤–∫–∞, —Ç—ë–ø–ª—ã–π —Ä–∞—Å—Å–µ—è–Ω–Ω—ã–π —Å–≤–µ—Ç
- mirror tiles, clean pastel background, soft highlights ‚Äî –∑–µ—Ä–∫–∞–ª—å–Ω–∞—è –ø–ª–∏—Ç–∫–∞, –ø–∞—Å—Ç–µ–ª—å

## 6) –ù–∞—Ç—É—Ä–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
- light wood table, soft daylight, eucalyptus leaves ‚Äî —Å–≤–µ—Ç–ª–æ–µ –¥–µ—Ä–µ–≤–æ, –¥–Ω–µ–≤–Ω–æ–π —Å–≤–µ—Ç, –∑–µ–ª–µ–Ω—å
- linen fabric folds, warm side light ‚Äî –ª—ë–Ω, —Å–∫–ª–∞–¥–∫–∏ —Ç–∫–∞–Ω–∏, —Ç—ë–ø–ª—ã–π –±–æ–∫–æ–≤–æ–π
- stone and wood surface, morning sunlight ‚Äî –∫–∞–º–µ–Ω—å+–¥–µ—Ä–µ–≤–æ, —É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–ª–Ω—Ü–µ

## 7) –ò–Ω—Ç–µ—Ä—å–µ—Ä
- cozy living room, wooden furniture, warm sunlight from window ‚Äî —É—é—Ç–Ω–∞—è –≥–æ—Å—Ç–∏–Ω–∞—è, —Ç—ë–ø–ª—ã–π —Å–≤–µ—Ç –∏–∑ –æ–∫–Ω–∞
- modern kitchen, clean surfaces, soft daylight ‚Äî —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫—É—Ö–Ω—è, —á–∏—Å—Ç—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏
- spa-style bathroom, stone, greenery, steam glow ‚Äî —Å–ø–∞-–≤–∞–Ω–Ω–∞—è, –∫–∞–º–µ–Ω—å, –ø–∞—Ä–æ–≤–æ–µ —Å–≤–µ—á–µ–Ω–∏–µ

## 8) –£–∫—Ä–∞—à–µ–Ω–∏–µ –Ω–∞ —á–µ–ª–æ–≤–µ–∫–µ (–∞–≤—Ç–æ–≥–µ–Ω)
- photorealistic human portrait, neutral background, visible neck and collarbone, soft diffused light, shallow depth of field, natural skin tones ‚Äî –ø–æ—Ä—Ç—Ä–µ—Ç, –≤–∏–¥–Ω–∞ —à–µ—è/–∫–ª—é—á–∏—Ü—ã, –º—è–≥–∫–∏–π —Å–≤–µ—Ç
- beauty close-up, neutral background, film grain, warm tones ‚Äî –±—å—é—Ç–∏-–∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–æ–Ω
- editorial style portrait, soft backlight glow, minimal makeup ‚Äî —Ñ—ç—à–Ω-–ø–æ—Ä—Ç—Ä–µ—Ç, –º—è–≥–∫–∞—è –ø–æ–¥—Å–≤–µ—Ç–∫–∞

## 9) –í —Ä—É–∫–∞—Ö (–∞–≤—Ç–æ–≥–µ–Ω)
- photorealistic hands close-up, neutral background, soft window light, macro-friendly composition ‚Äî –∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω —Ä—É–∫, –º—è–≥–∫–∏–π —Å–≤–µ—Ç –∏–∑ –æ–∫–Ω–∞
- female hands, natural skin texture, shallow depth of field ‚Äî –∂–µ–Ω—Å–∫–∏–µ —Ä—É–∫–∏, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–æ–∂–∞, –º–∞–ª–∞—è –ì–†–ò–ü
- hands holding space, warm interior bokeh, cozy mood ‚Äî —Ä—É–∫–∏ —Å ¬´–ø—É—Å—Ç—ã–º –º–µ—Å—Ç–æ–º¬ª, —Ç—ë–ø–ª–æ–µ –±–æ–∫–µ

## 10) –°–µ–∑–æ–Ω—ã
**–õ–µ—Ç–æ**
- sunlight, leaf shadows, warm tones ‚Äî —Å–æ–ª–Ω–µ—á–Ω—ã–π —Å–≤–µ—Ç, —Ç–µ–Ω–∏ –ª–∏—Å—Ç–≤—ã
- beach sand, soft waves, bright sky ‚Äî –ø–ª—è–∂, –≤–æ–ª–Ω—ã, —è—Ä–∫–æ–µ –Ω–µ–±–æ

**–û—Å–µ–Ω—å**
- golden hour light, autumn leaves, cozy atmosphere ‚Äî –∑–æ–ª–æ—Ç–æ–π —á–∞—Å, –ª–∏—Å—Ç—å—è, —É—é—Ç
- wooden table, pumpkins, warm side light ‚Äî —Å—Ç–æ–ª, —Ç—ã–∫–≤—ã, —Ç—ë–ø–ª—ã–π –±–æ–∫–æ–≤–æ–π

**–ó–∏–º–∞**
- snow-covered branches, cold blue light ‚Äî —Å–Ω–µ–≥, —Ö–æ–ª–æ–¥–Ω—ã–π –≥–æ–ª—É–±–æ–π —Å–≤–µ—Ç
- cozy interior, fairy lights, Christmas mood ‚Äî —É—é—Ç, –≥–∏—Ä–ª—è–Ω–¥—ã, –Ω–æ–≤—ã–π –≥–æ–¥

**–í–µ—Å–Ω–∞**
- fresh greenery, blooming branches, soft sunlight ‚Äî —Å–≤–µ–∂–∞—è –∑–µ–ª–µ–Ω—å, —Ü–≤–µ—Ç—ã, –º—è–≥–∫–æ–µ —Å–æ–ª–Ω—Ü–µ
- pastel background, gentle glow ‚Äî –ø–∞—Å—Ç–µ–ª—å, –º—è–≥–∫–æ–µ —Å–≤–µ—á–µ–Ω–∏–µ

## 11) –ü—Ä–∞–∑–¥–Ω–∏–∫–∏ / –æ–≥–Ω–∏
- warm bokeh lights, dark background, cozy mood ‚Äî —Ç—ë–ø–ª–æ–µ –±–æ–∫–µ –Ω–∞ —Ç—ë–º–Ω–æ–º
- bright garlands, festive atmosphere ‚Äî —è—Ä–∫–∏–µ –≥–∏—Ä–ª—è–Ω–¥—ã, –ø—Ä–∞–∑–¥–Ω–∏–∫
- fireworks background, high contrast ‚Äî —Ñ–µ–π–µ—Ä–≤–µ—Ä–∫–∏, –∫–æ–Ω—Ç—Ä–∞—Å—Ç

## 12) Flat Lay (–≤–∏–¥ —Å–≤–µ—Ä—Ö—É)
- top view, matte surface, soft light, minimal props ‚Äî –≤–∏–¥ —Å–≤–µ—Ä—Ö—É, –º–∞—Ç–æ–≤–∞—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å
- pastel background, neat composition ‚Äî –ø–∞—Å—Ç–µ–ª—å, –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è —Ä–∞—Å–∫–ª–∞–¥–∫–∞
- wooden table, props around edges, soft shadows ‚Äî –¥–µ—Ä–µ–≤–æ, —Ä–µ–∫–≤–∏–∑–∏—Ç –ø–æ –∫—Ä–∞—è–º

## 13) –¢–µ—Ö–Ω–æ / –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π
- smooth concrete, cold directional light, graphic shadows ‚Äî –≥–ª–∞–¥–∫–∏–π –±–µ—Ç–æ–Ω, —Ö–æ–ª–æ–¥–Ω—ã–π —Å–≤–µ—Ç
- metallic surface, reflections, blue highlights ‚Äî –º–µ—Ç–∞–ª–ª, –æ—Ç—Ä–∞–∂–µ–Ω–∏—è, —Å–∏–Ω–∏–µ –∞–∫—Ü–µ–Ω—Ç—ã
- neon accents, black background ‚Äî –Ω–µ–æ–Ω, —á—ë—Ä–Ω—ã–π —Ñ–æ–Ω

## 14) –£—Å–∏–ª–∏—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (–¥–æ–±–∞–≤–ª—è–π –≤ –∫–æ–Ω–µ—Ü)
- photorealistic, ultra detailed, 8k
- studio softbox lighting, realistic textures
- centered composition, generous negative space
- natural soft shadows
- no props, no text
"""

# ====== STATES ======
class GenStates(StatesGroup):
    waiting_start = State()
    waiting_photo = State()
    waiting_service = State()
    waiting_placement = State()  # —Å—Ç—É–¥–∏—è / –Ω–∞ —á–µ–ª–æ–≤–µ–∫–µ / –≤ —Ä—É–∫–∞—Ö (–∞–≤—Ç–æ–≥–µ–Ω)
    waiting_size = State()       # –≤—ã–±–æ—Ä —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω
    waiting_variants = State()   # —Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    waiting_style = State()

# ====== CHOICES & KEYBOARDS ======
class CutService(str, Enum):
    REMBG = "–≠–∫–æ–Ω–æ–º (RemBG ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω–æ)"
    PIXELCUT = "–ü—Ä–µ–º–∏—É–º (Pixelcut ‚Äî –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ)"

class Placement(str, Enum):
    STUDIO = "–°—Ç—É–¥–∏–π–Ω–æ (–Ω–∞ —Ñ–æ–Ω–µ)"
    ON_BODY = "–ù–∞ —á–µ–ª–æ–≤–µ–∫–µ (—É–∫—Ä–∞—à–µ–Ω–∏–µ/–æ–¥–µ–∂–¥–∞)"
    IN_HAND = "–í —Ä—É–∫–∞—Ö (–∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω)"

start_kb = types.ReplyKeyboardMarkup(resize_keyboard=True)
start_kb.add(types.KeyboardButton("–°–¢–ê–†–¢"))
start_kb.add(types.KeyboardButton("üìì –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ –ø—Ä–æ–º—Ç–∞–º"))

CUT_KB = types.ReplyKeyboardMarkup(resize_keyboard=True)
CUT_KB.add(CutService.REMBG.value)
CUT_KB.add(CutService.PIXELCUT.value)

PLACEMENT_KB = types.ReplyKeyboardMarkup(resize_keyboard=True)
PLACEMENT_KB.add(Placement.STUDIO.value)
PLACEMENT_KB.add(Placement.ON_BODY.value)
PLACEMENT_KB.add(Placement.IN_HAND.value)

PRESETS = [
    "–ö–∞—Ç–∞–ª–æ–≥: —á–∏—Å—Ç—ã–π —Å—Ç—É–¥–∏–π–Ω—ã–π —Ñ–æ–Ω, –º—è–≥–∫–∏–π –≥—Ä–∞–¥–∏–µ–Ω—Ç, –∞–∫–∫—É—Ä–∞—Ç–Ω–∞—è —Ç–µ–Ω—å",
    "–ú–∏–Ω–∏–º–∞–ª–∏–∑–º: –æ–¥–Ω–æ—Ç–æ–Ω–Ω—ã–π –º–∞—Ç–æ–≤—ã–π —Ñ–æ–Ω, –º—è–≥–∫–∏–µ —Ç–µ–Ω–∏",
    "–°–≤–µ—Ç–ª—ã–π –º–æ–Ω–æ—Ö—Ä–æ–º: high-key, —Ä–æ–≤–Ω—ã–π –¥–Ω–µ–≤–Ω–æ–π —Å–≤–µ—Ç",
    "–¢—ë–º–Ω—ã–π –º–æ–Ω–æ—Ö—Ä–æ–º: low-key, –≥–ª—É–±–æ–∫–∏–µ —Ç–µ–Ω–∏, –∫–æ–Ω—Ç—Ä–æ–≤—ã–π —Å–≤–µ—Ç",
    "Luxury: –≥–ª—è–Ω—Ü–µ–≤—ã–π –∫–∞–º–µ–Ω—å/–º—Ä–∞–º–æ—Ä, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –±–ª–∏–∫–∏",
    "Nature-mood: –¥–µ—Ä–µ–≤–æ, –ª–µ–Ω, –∑–µ–ª–µ–Ω—å, —Ä–∞—Å—Å–µ—è–Ω–Ω—ã–π —Å–≤–µ—Ç",
    "Flat lay: –≤–∏–¥ —Å–≤–µ—Ä—Ö—É, –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–æ–ø—Å—ã",
    "–ö–æ—Å–º–µ—Ç–∏–∫–∞: –º–∞—Ç–æ–≤—ã–π –∞–∫—Ä–∏–ª, —Å—Ç–µ–∫–ª–æ, –º—è–≥–∫–∏–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è",
    "–£–∫—Ä–∞—à–µ–Ω–∏—è: –±–∞—Ä—Ö–∞—Ç, –º–∞–∫—Ä–æ-—Å–≤–µ—Ç, –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ –±–ª–∏–∫–∏",
    "–ï–¥–∞/–≤—ã–ø–µ—á–∫–∞: –¥–µ—Ä–µ–≤—è–Ω–Ω—ã–π —Å—Ç–æ–ª, —Ç—ë–ø–ª—ã–π —É—Ç—Ä–µ–Ω–Ω–∏–π —Å–≤–µ—Ç",
    "–¢–µ—Ö–Ω–∏–∫–∞: –±–µ—Ç–æ–Ω/–∞–ª—é–º–∏–Ω–∏–π, —Ö–æ–ª–æ–¥–Ω—ã–π —Å–≤–µ—Ç, –≥–µ–æ–º–µ—Ç—Ä–∏—è",
    "–ü—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–π: –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ñ–æ–Ω, —Ç—ë–ø–ª–æ–µ –±–æ–∫–µ –æ–≥–Ω–µ–π",
    "–õ–µ—Ç–æ/–∞—É—Ç–¥–æ—Ä: —Ç—ë–ø–ª—ã–π —Å–æ–ª–Ω–µ—á–Ω—ã–π —Å–≤–µ—Ç, —Ç–µ–Ω–∏ –ª–∏—Å—Ç–≤—ã",
    "–ö–∞–º–µ–Ω—å/–º—Ä–∞–º–æ—Ä: –ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º—Ä–∞–º–æ—Ä, –º—è–≥–∫–∏–µ –±–ª–∏–∫–∏",
    "–ë–µ—Ç–æ–Ω: –≥–ª–∞–¥–∫–∏–π —Å–µ—Ä—ã–π –±–µ—Ç–æ–Ω, –≥—Ä–∞—Ñ–∏—á–Ω—ã–µ —Ç–µ–Ω–∏",
    "–õ—ë–Ω/—Ç–µ–∫—Å—Ç–∏–ª—å: –º—è–≥–∫–∏–µ —Å–∫–ª–∞–¥–∫–∏, –¥–Ω–µ–≤–Ω–æ–π —Å–≤–µ—Ç",
]
STYLE_KB = types.ReplyKeyboardMarkup(resize_keyboard=True)
for p in PRESETS:
    STYLE_KB.add(types.KeyboardButton(p))
STYLE_KB.add(types.KeyboardButton("–°–≤–æ—è —Å—Ü–µ–Ω–∞ (–æ–ø–∏—à—É —Ç–µ–∫—Å—Ç–æ–º)"))

OPENAI_IMAGES_ENDPOINT = "https://api.openai.com/v1/images/generations"

SIZE_KB = types.ReplyKeyboardMarkup(resize_keyboard=True)
for s in ["1:1", "4:5", "3:4", "16:9", "9:16"]:
    SIZE_KB.add(types.KeyboardButton(s))

VAR_KB = types.ReplyKeyboardMarkup(resize_keyboard=True)
for n in ["1", "2", "3", "4", "5"]:
    VAR_KB.add(types.KeyboardButton(n))

# ===== ACCESS =====
def check_user_access(user_id: int) -> bool:
    if ADMIN_ID and user_id == ADMIN_ID:
        return True
    return True  # –¥–ª—è —Ç–µ—Å—Ç–æ–≤ –ø—É—Å–∫–∞–µ–º –≤—Å–µ—Ö

# ====== HELPERS ======
async def load_bytes_by_file_id(bot: Bot, file_id: str) -> bytes:
    """–°–∫–∞—á–∞—Ç—å –±–∞–π—Ç—ã –∏—Å—Ö–æ–¥–Ω–∏–∫–∞ –ø–æ Telegram file_id (–Ω—É–∂–Ω–æ –¥–ª—è /repeat)."""
    f = await bot.get_file(file_id)
    fb = await bot.download_file(f.file_path)
    return fb.read()

def ensure_prompts_file():
    if not PROMPTS_FILE.exists():
        PROMPTS_FILE.write_text(PROMPTS_MD, encoding="utf-8")

def remove_bg_rembg(image_bytes: bytes) -> bytes:
    if not REMBG_AVAILABLE:
        raise RuntimeError("rembg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏: pip install rembg")
    return rembg_remove(
        image_bytes,
        alpha_matting=True,
        alpha_matting_foreground_threshold=240,
        alpha_matting_background_threshold=10,
        alpha_matting_erode_size=5,
    )

def remove_bg_pixelcut(image_bytes: bytes) -> bytes:
    if not PIXELCUT_API_KEY or not PIXELCUT_ENDPOINT:
        raise RuntimeError("–ù–µ –∑–∞–¥–∞–Ω PIXELCUT_API_KEY –∏–ª–∏ PIXELCUT_ENDPOINT")
    headers = {"X-API-KEY": PIXELCUT_API_KEY}
    files = {
        "image": ("image.png", image_bytes, "image/png"),
        "image_file": ("image.png", image_bytes, "image/png"),
    }
    resp = requests.post(PIXELCUT_ENDPOINT, headers=headers, files=files, timeout=90)
    if resp.status_code != 200:
        raise RuntimeError(f"Pixelcut error {resp.status_code}: {resp.text}")
    ctype = resp.headers.get("Content-Type", "")
    if "image/" in ctype or resp.content.startswith(b"\x89PNG") or resp.content.startswith(b"\xff\xd8"):
        return resp.content
    try:
        data = resp.json()
        url = (
            data.get("result_url")
            or data.get("url")
            or (data.get("data", {}).get("url") if isinstance(data.get("data"), dict) else None)
        )
        if not url:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ result_url/url –≤ –æ—Ç–≤–µ—Ç–µ Pixelcut")
        img = requests.get(url, timeout=90)
        img.raise_for_status()
        return img.content
    except Exception:
        raise RuntimeError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ Pixelcut: {resp.text[:400]}")

def pick_openai_size(aspect: str) -> str:
    # gpt-image-1: 1024x1024, 1024x1792 (–ø–æ—Ä—Ç—Ä–µ—Ç ~9:16), 1792x1024 (–ª–∞–Ω–¥—à–∞—Ñ—Ç ~16:9)
    if aspect == "1:1":
        return "1024x1024"
    if aspect in ("4:5", "3:4", "9:16"):
        return "1024x1792"   # –ø–æ—Ä—Ç—Ä–µ—Ç
    if aspect == "16:9":
        return "1792x1024"   # –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å
    return "1024x1024"

def center_crop_to_aspect(img: Image.Image, aspect: str) -> Image.Image:
    w, h = img.size
    targets = {"1:1": 1/1, "4:5": 4/5, "3:4": 3/4, "16:9": 16/9, "9:16": 9/16}
    if aspect not in targets:
        return img
    r = targets[aspect]
    cur = w / h
    if abs(cur - r) < 1e-3:
        return img
    if cur > r:
        new_w = int(h * r)
        x1 = (w - new_w) // 2
        return img.crop((x1, 0, x1 + new_w, h))
    else:
        new_h = int(w / r)
        y1 = (h - new_h) // 2
        return img.crop((0, y1, w, y1 + new_h))

def generate_background(prompt: str, size: str = "1024x1024") -> Image.Image:
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": "gpt-image-1",
        "prompt": (
            "High-quality product photography background only (no product). "
            "Cinematic lighting, realistic textures. " + prompt
        ),
        "size": size,
        "n": 1,
    }
    r = requests.post(OPENAI_IMAGES_ENDPOINT, headers=headers, json=payload, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"OpenAI image gen error {r.status_code}: {r.text}")
    b64 = r.json()["data"][0]["b64_json"]
    bg_bytes = base64.b64decode(b64)
    return Image.open(io.BytesIO(bg_bytes)).convert("RGBA")

def compose_subject_on_bg(
    subject_png: bytes,
    bg_img: Image.Image,
    *,
    scale_by_height: float = 0.75,
    x_shift: float = 0.0,
    y_shift: float = -0.05,
) -> Image.Image:
    """–ü—Ä–æ—Å—Ç–∞—è –∫–æ–º–ø–æ–Ω–æ–≤–∫–∞ + –º—è–≥–∫–∞—è —Ç–µ–Ω—å (–±–µ–∑ cv2)."""
    subj = Image.open(io.BytesIO(subject_png)).convert("RGBA")
    canvas_w, canvas_h = bg_img.size
    target_h = int(canvas_h * scale_by_height)
    scale = target_h / max(1, subj.height)
    subj = subj.resize(
        (max(1, int(subj.width * scale)), max(1, int(subj.height * scale))),
        Image.LANCZOS,
    )

    alpha = subj.split()[-1]
    shadow = Image.new("RGBA", subj.size, (0, 0, 0, 160))
    shadow.putalpha(alpha)
    shadow = shadow.filter(ImageFilter.GaussianBlur(12))

    out = bg_img.copy()
    x = int((canvas_w - subj.width) * 0.5 + x_shift * canvas_w)
    y = int(canvas_h - subj.height + y_shift * canvas_h)

    out.alpha_composite(shadow, (x + 8, y + 18))
    out.alpha_composite(subj, (x, y))
    return out

def seamless_place(
    subject_png: bytes,
    back_img: Image.Image,
    *,
    scale_by_height: float,
    x: int,
    y: int,
) -> Image.Image:
    """
    –ú—è–≥–∫–æ ¬´–≤–∂–∏–≤–ª—è–µ—Ç¬ª –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–π –ø—Ä–µ–¥–º–µ—Ç –≤ —Ñ–æ–Ω (cv2.seamlessClone).
    x, y ‚Äî –ø–æ–∑–∏—Ü–∏—è –ª–µ–≤–æ–≥–æ-–≤–µ—Ä—Ö–Ω–µ–≥–æ —É–≥–ª–∞ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ (—Ü–µ–Ω—Ç—Ä –±—É–¥–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω).
    """
    fore = Image.open(io.BytesIO(subject_png)).convert("RGBA")
    back = back_img.convert("RGB")

    bw, bh = back.size
    target_h = int(bh * scale_by_height)
    ratio = target_h / max(1, fore.height)
    fore = fore.resize((max(1, int(fore.width * ratio)), target_h), Image.LANCZOS)

    fore_rgb = cv2.cvtColor(np.array(fore.convert("RGB")), cv2.COLOR_RGB2BGR)
    back_bgr = cv2.cvtColor(np.array(back), cv2.COLOR_RGB2BGR)
    mask = np.array(fore.split()[-1])

    fh, fw = fore_rgb.shape[:2]
    x = max(0, min(back_bgr.shape[1] - fw, x))
    y = max(0, min(back_bgr.shape[0] - fh, y))

    canvas = np.zeros_like(back_bgr)
    canvas[y:y+fh, x:x+fw] = fore_rgb

    mask_full = np.zeros(back_bgr.shape[:2], dtype=np.uint8)
    mask_full[y:y+fh, x:x+fw] = mask

    center = (x + fw // 2, y + fh // 2)
    mixed = cv2.seamlessClone(canvas, back_bgr, mask_full, center, cv2.NORMAL_CLONE)
    return Image.fromarray(cv2.cvtColor(mixed, cv2.COLOR_BGR2RGB))

# ====== BOT HANDLERS ======
@dp.message_handler(commands=["start"])
async def cmd_start(message: types.Message, state: FSMContext):
    if not check_user_access(message.from_user.id):
        await message.answer(f"‚õî –ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞. –ü–æ–ª—É—á–∏—Ç–µ –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ @{MAIN_BOT_USERNAME}.")
        return
    await state.finish()
    ensure_prompts_file()
    await message.answer(WELCOME, reply_markup=start_kb)
    await GenStates.waiting_start.set()

@dp.message_handler(lambda m: (m.text or "").strip().upper() == "–°–¢–ê–†–¢", state=GenStates.waiting_start)
async def on_press_start(message: types.Message, state: FSMContext):
    await message.answer(REQUIREMENTS, reply_markup=types.ReplyKeyboardRemove())
    try:
        with open(PROMPTS_FILE, "rb") as f:
            await message.answer_document(
                types.InputFile(f, filename=PROMPTS_FILE.name),
                caption="üìì –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ –ø—Ä–æ–º–ø—Ç–∞–º",
            )
    except FileNotFoundError:
        await message.answer("‚ö†Ô∏è –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
    await message.answer("–ü—Ä–∏—à–ª–∏ —Ñ–æ—Ç–æ —Ç–æ–≤–∞—Ä–∞ (–ª—É—á—à–µ –∫–∞–∫ –î–æ–∫—É–º–µ–Ω—Ç).")
    await GenStates.waiting_photo.set()

@dp.message_handler(state=GenStates.waiting_start, regexp="^üìì –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ –ø—Ä–æ–º—Ç–∞–º$")
async def send_cheatsheet(message: types.Message, state: FSMContext):
    ensure_prompts_file()
    try:
        with open(PROMPTS_FILE, "rb") as f:
            await message.answer_document(
                types.InputFile(f, filename=PROMPTS_FILE.name),
                caption="üìì –®–ø–∞—Ä–≥–∞–ª–∫–∞ –ø–æ –ø—Ä–æ–º–ø—Ç–∞–º",
            )
    except FileNotFoundError:
        await message.answer("‚ö†Ô∏è –§–∞–π–ª —Å–æ —à–ø–∞—Ä–≥–∞–ª–∫–æ–π –Ω–µ –Ω–∞–π–¥–µ–Ω.")

@dp.message_handler(state=GenStates.waiting_photo, content_types=["photo", "document"])
async def got_photo(message: types.Message, state: FSMContext):
    # –ü–æ–ª—É—á–∞–µ–º file_id –¥–ª—è –≥–∞–ª–µ—Ä–µ–∏ –∏ –±–∞–π—Ç—ã –¥–ª—è –≤—ã—Ä–µ–∑–∫–∏
    if message.document:
        src_file_id = message.document.file_id
        f = await bot.get_file(message.document.file_id)
    else:
        src_file_id = message.photo[-1].file_id
        f = await bot.get_file(message.photo[-1].file_id)
    fb = await bot.download_file(f.file_path)
    await state.update_data(image=fb.read(), image_file_id=src_file_id)

    await message.answer("–ß–µ–º –≤—ã—Ä–µ–∑–∞—Ç—å —Ñ–æ–Ω?", reply_markup=CUT_KB)
    await GenStates.waiting_service.set()

@dp.message_handler(state=GenStates.waiting_service, content_types=["text"])
async def choose_service(message: types.Message, state: FSMContext):
    choice = (message.text or "").strip()
    if choice not in (CutService.REMBG.value, CutService.PIXELCUT.value):
        await message.answer("–í—ã–±–µ—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ.")
        return
    await state.update_data(cut_service=choice)

    await message.answer("–í—ã–±–µ—Ä–∏ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞:", reply_markup=PLACEMENT_KB)
    await GenStates.waiting_placement.set()

@dp.message_handler(state=GenStates.waiting_placement, content_types=["text"])
async def choose_placement(message: types.Message, state: FSMContext):
    val = (message.text or "").strip()
    if val not in (Placement.STUDIO.value, Placement.ON_BODY.value, Placement.IN_HAND.value):
        await message.answer("–í—ã–±–µ—Ä–∏ –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤.")
        return
    await state.update_data(placement=val)

    await message.answer("–í—ã–±–µ—Ä–∏ —Ä–∞–∑–º–µ—Ä (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω):", reply_markup=SIZE_KB)
    await GenStates.waiting_size.set()

@dp.message_handler(state=GenStates.waiting_size, content_types=["text"])
async def choose_size(message: types.Message, state: FSMContext):
    size = (message.text or "").strip()
    if size not in {"1:1", "4:5", "3:4", "16:9", "9:16"}:
        await message.answer("–í—ã–±–µ—Ä–∏ –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ.")
        return
    await state.update_data(size_aspect=size)
    await message.answer("–°–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å–¥–µ–ª–∞—Ç—å –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑?", reply_markup=VAR_KB)
    await GenStates.waiting_variants.set()

@dp.message_handler(state=GenStates.waiting_variants, content_types=["text"])
async def choose_variants(message: types.Message, state: FSMContext):
    try:
        n = int((message.text or "1").strip())
    except ValueError:
        n = 1
    n = max(1, min(5, n))
    await state.update_data(n_variants=n)
    txt = (
        "–í—ã–±–µ—Ä–∏ —Å—Ü–µ–Ω—É –∏–ª–∏ –æ–ø–∏—à–∏ —Å–≤–æ—é.\n\n"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ –ø—Ä–æ–º–ø—Ç–∞–º:\n"
        "‚Ä¢ –ö–∞—Ç–∞–ª–æ–≥ ‚Äî clean studio background, soft gradient, subtle shadow.\n"
        "‚Ä¢ Lifestyle ‚Äî warm interior corner, wood, linen, soft window light.\n"
        "‚Ä¢ Luxury ‚Äî glossy stone, controlled highlights, dark backdrop.\n\n"
        "–°–æ–≤–µ—Ç: –æ—Ç–ø—Ä–∞–≤–ª—è–π –∏—Å—Ö–æ–¥–Ω–∏–∫–∏ –∫–∞–∫ *–î–æ–∫—É–º–µ–Ω—Ç* ‚Äî Telegram –Ω–µ —Å–∂–∏–º–∞–µ—Ç —Ñ–æ—Ç–æ."
    )
    await message.answer(txt, reply_markup=STYLE_KB, parse_mode="Markdown")
    await GenStates.waiting_style.set()

@dp.message_handler(state=GenStates.waiting_style, content_types=["text"])
async def got_style(message: types.Message, state: FSMContext):
    style_text = (message.text or "").strip()
    await state.update_data(style=style_text)
    await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é‚Ä¶", reply_markup=types.ReplyKeyboardRemove())

    try:
        data = await state.get_data()

        # 0) –ø–æ–¥—Ç—è–Ω—É—Ç—å –±–∞–π—Ç—ã –∏—Å—Ö–æ–¥–Ω–∏–∫–∞ –ø–æ file_id, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–¥–ª—è /repeat)
        image_bytes = data.get("image")
        if image_bytes is None:
            src_id = data.get("image_file_id")
            if not src_id:
                raise RuntimeError("–ù–µ—Ç –∏—Å—Ö–æ–¥–Ω–∏–∫–∞: –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start.")
            image_bytes = await load_bytes_by_file_id(bot, src_id)
            await state.update_data(image=image_bytes)

        cut_service = data["cut_service"]
        placement = data.get("placement", Placement.STUDIO.value)
        size_aspect = data.get("size_aspect", "1:1")
        n_variants = int(data.get("n_variants", 1))

        openai_size = pick_openai_size(size_aspect)

        # 1) –≤—ã—Ä–µ–∑–∞–µ–º –æ–¥–∏–Ω —Ä–∞–∑
        if cut_service == CutService.PIXELCUT.value:
            cut_png = remove_bg_pixelcut(image_bytes)
        else:
            cut_png = remove_bg_rembg(image_bytes)

        result_file_ids = []

        for i in range(n_variants):
            # 2) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–æ–Ω
            if placement == Placement.STUDIO.value:
                prompt = (
                    f"{style_text}. Background only, no product. "
                    "photorealistic, studio lighting, realistic textures, no text."
                )
            elif placement == Placement.ON_BODY.value:
                prompt = (
                    f"{style_text}. photorealistic human portrait, neutral background, "
                    "visible neck and collarbone, soft diffused light, shallow depth of field, "
                    "natural skin tones, allow central empty area for necklace, no text."
                )
            else:  # IN_HAND
                prompt = (
                    f"{style_text}. photorealistic hands close-up, neutral background, soft window light, "
                    "macro-friendly composition, allow central empty area for product, no text."
                )

            bg = generate_background(prompt, size=openai_size)
            bg = center_crop_to_aspect(bg, size_aspect)

            # 3) –∫–æ–º–ø–æ–Ω–æ–≤–∫–∞
            if placement == Placement.STUDIO.value:
                result = compose_subject_on_bg(
                    cut_png, bg, scale_by_height=0.74, x_shift=0.0, y_shift=-0.06
                )
            elif placement == Placement.ON_BODY.value:
                bw, bh = bg.size
                x = bw // 2 - 1
                y = int(bh * 0.38)  # –∑–æ–Ω–∞ —à–µ–∏
                result = seamless_place(cut_png, bg, scale_by_height=0.26, x=x, y=y)
            else:  # IN_HAND
                bw, bh = bg.size
                x = bw // 2 - 1
                y = int(bh * 0.5)   # —Ü–µ–Ω—Ç—Ä
                result = seamless_place(cut_png, bg, scale_by_height=0.40, x=x, y=y)

            # 4) –æ—Ç–ø—Ä–∞–≤–∫–∞
            buf = io.BytesIO()
            result.save(buf, format="PNG")
            buf.seek(0)
            filename = f"product_{i+1}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.png"
            sent = await message.answer_document(
                types.InputFile(buf, filename=filename),
                caption=f"–í–∞—Ä–∏–∞–Ω—Ç {i+1}/{n_variants}",
            )
            if sent and sent.document:
                result_file_ids.append(sent.document.file_id)

        # 5) —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–∞–ø–∏—Å—å –≤ –≥–∞–ª–µ—Ä–µ–µ (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏ file_id)
        try:
            src_id = data.get("image_file_id", "")
            gallery_save(
                message.from_user.id,
                src_file_id=src_id,
                cut_file_id="",  # –≤—ã—Ä–µ–∑–∫—É –≤ –¢–ì –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º ‚Äî –ø—É—Å—Ç–æ
                placement=placement,
                size_aspect=size_aspect,
                style_text=style_text,
                n_variants=n_variants,
                result_file_ids=result_file_ids,
            )
        except Exception as e:
            logging.warning(f"Gallery save failed: {e}")

    except Exception as e:
        logging.exception("Generation error")
        await message.answer(f"–û—à–∏–±–∫–∞: {e}")

    await state.finish()
    await message.answer("–ü—Ä–∏—à–ª–∏ –µ—â—ë —Ñ–æ—Ç–æ –∏–ª–∏ /start.")

@dp.message_handler(commands=["repeat"])
async def repeat_last(message: types.Message, state: FSMContext):
    row = gallery_last(message.from_user.id)
    if not row:
        await message.answer("–í –≥–∞–ª–µ—Ä–µ–µ –ø–æ–∫–∞ –ø—É—Å—Ç–æ. –°–Ω–∞—á–∞–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ñ–æ—Ç–æ.")
        return
    _id, src_file_id, cut_file_id, placement, size_aspect, style_text = row
    await state.update_data(
        image_file_id=src_file_id,
        placement=placement,
        size_aspect=size_aspect,
        n_variants=1,
    )
    await message.answer(
        "–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏. –í—ã–±–µ—Ä–∏ —Å—Ç–∏–ª—å/–ø—Ä–µ—Å–µ—Ç –∏–ª–∏ –Ω–∞–ø–∏—à–∏ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç.",
        reply_markup=STYLE_KB,
    )
    await GenStates.waiting_style.set()

# --- webhook config for Render (aiogram v2) ---
WEBHOOK_PATH = f"/webhook/{BOT_TOKEN}"
WEBHOOK_BASE_URL = os.getenv("WEBHOOK_BASE_URL", "").rstrip("/")
assert WEBHOOK_BASE_URL, "WEBHOOK_BASE_URL is required"
WEBHOOK_URL = f"{WEBHOOK_BASE_URL}{WEBHOOK_PATH}"

WEBAPP_HOST = "0.0.0.0"
WEBAPP_PORT = int(os.environ.get("PORT", 10000))

async def on_startup(dp):
    await bot.set_webhook(WEBHOOK_URL)
    await _log_bot_info()
    logging.info("Webhook set: %s", WEBHOOK_URL)

async def on_shutdown(dp):
    logging.info("Shutting down‚Ä¶")
    await bot.delete_webhook()

if __name__ == "__main__":
    start_webhook(
        dispatcher=dp,
        webhook_path=WEBHOOK_PATH,
        on_startup=on_startup,
        on_shutdown=on_shutdown,
        skip_updates=True,
        host=WEBAPP_HOST,
        port=WEBAPP_PORT,
    )
